{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Twitter Sentiment** **Analysis** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "Sentiment analysis refers to identifying as well as classifying the sentiments that are expressed in the text source. Tweets are often useful in generating a vast amount of sentiment data upon analysis. These data are useful in understanding the opinion of the people about a variety of topics.\n",
    "\n",
    "The aim to analyze the sentiment of the tweets provided from the Sentiment140 dataset by developing a machine learning pipeline involving the use of various classifiers . The performance of these classifiers is then evaluated using K-fold cross Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement** :-\n",
    "In this project, we try to implement a Twitter sentiment analysis model that helps to overcome the challenges of identifying the sentiments of the tweets. The necessary details regarding the dataset are:\n",
    "\n",
    "The dataset provided is the Sentiment140 Dataset which consists of 1,600,000 tweets that have been extracted using the Twitter API. The various columns present in the dataset are:\n",
    "\n",
    "**target**: the polarity of the tweet (positive or negative)\n",
    "\n",
    "**ids**: Unique id of the tweet\n",
    "\n",
    "**date**: the date of the tweet\n",
    "\n",
    "**flag**: It refers to the query. If no such query exists then it is NO QUERY.\n",
    "\n",
    "**user**: It refers to the name of the user that tweeted\n",
    "\n",
    "**text**: It refers to the text of the tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Pipeline**\n",
    "\n",
    "The various steps involved in the Machine Learning Pipeline are :\n",
    "\n",
    "Import Necessary Libraries\n",
    "\n",
    "Read and Load the Dataset\n",
    "\n",
    "Exploratory Data Analysis\n",
    "\n",
    "Data Visualization of Target Variables\n",
    "\n",
    "Data Preprocessing\n",
    "\n",
    "Splitting our data into Train and Test Subset\n",
    "\n",
    "Function For Model Evaluation\n",
    "\n",
    "Model Building\n",
    "\n",
    "Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step-1: Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step-2: Read and Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET_COLUMNS=['target','ids','date','flag','user','text']\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "dataset = pd.read_csv('C:\\\\Users\\\\DELL\\\\Downloads\\\\trainingandtestdata\\\\training.1600000.processed.noemoticon.csv',encoding=DATASET_ENCODING,names=DATASET_COLUMNS, skiprows=795000, nrows = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step-3: Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.1: Five top records of data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2327192646</td>\n",
       "      <td>Thu Jun 25 08:02:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>quiz_master</td>\n",
       "      <td>Was having dinner with parents downstairs in D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2327193206</td>\n",
       "      <td>Thu Jun 25 08:02:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>djcampos</td>\n",
       "      <td>Blah 5am still up  daang I got deep problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2327193455</td>\n",
       "      <td>Thu Jun 25 08:02:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RKF</td>\n",
       "      <td>@jenspeedy I would suggest avoiding 360 Living...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2327193641</td>\n",
       "      <td>Thu Jun 25 08:02:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AnaHertz</td>\n",
       "      <td>@alexbroun I didn't convince myself I was fat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2327193806</td>\n",
       "      <td>Thu Jun 25 08:02:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>yenafer</td>\n",
       "      <td>@spotzle @jstarrh check on sunscreen, snacks, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag         user  \\\n",
       "0       0  2327192646  Thu Jun 25 08:02:13 PDT 2009  NO_QUERY  quiz_master   \n",
       "1       0  2327193206  Thu Jun 25 08:02:16 PDT 2009  NO_QUERY     djcampos   \n",
       "2       0  2327193455  Thu Jun 25 08:02:17 PDT 2009  NO_QUERY          RKF   \n",
       "3       0  2327193641  Thu Jun 25 08:02:18 PDT 2009  NO_QUERY     AnaHertz   \n",
       "4       0  2327193806  Thu Jun 25 08:02:18 PDT 2009  NO_QUERY      yenafer   \n",
       "\n",
       "                                                text  \n",
       "0  Was having dinner with parents downstairs in D...  \n",
       "1       Blah 5am still up  daang I got deep problems  \n",
       "2  @jenspeedy I would suggest avoiding 360 Living...  \n",
       "3  @alexbroun I didn't convince myself I was fat ...  \n",
       "4  @spotzle @jstarrh check on sunscreen, snacks, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.2: Shape of data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.3: Data information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   target  10000 non-null  int64 \n",
      " 1   ids     10000 non-null  int64 \n",
      " 2   date    10000 non-null  object\n",
      " 3   flag    10000 non-null  object\n",
      " 4   user    10000 non-null  object\n",
      " 5   text    10000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3.4 : Checking for missing values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "ids       0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step-4: Data Visualization of Target Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='target', data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step-5: Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5.1: Selecting the text and Target column for our further analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataset[['text','target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5.2: Print unique values of target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5.3: Replacing the values to ease understanding. (Assigning 1 to Positive sentiment 4)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-54c9eb4fa536>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['target'] = data['target'].replace(4,1)\n"
     ]
    }
   ],
   "source": [
    "data['target'] = data['target'].replace(4,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5.4: Print unique values of target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 5.5 : Importing necessary Dependencies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5.6: Cleaning the tweet text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for i in range(0, int(data.shape[0])):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', data['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    lm = nltk.WordNetLemmatizer()\n",
    "    review = [lm.lemmatize(word) for word in review]\n",
    "    review = ' '.join(review)\n",
    "    text.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5.7: Creating bag of words model / Getting tokenization of tweet text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5.8: Fit the CountVectorizer and transform the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step-6: Splitting our dataset into Train and Test Subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.05, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step-7: Function For Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*K-fold cross Validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import accuracy_score\n",
    "def model_Evaluate(model, x_test,  y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step-8: Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We will train various models and compare their accuracies to get the model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models used :**\n",
    "\n",
    "  Logistic Regression\n",
    "\n",
    "  K-Nearest Neighbors\n",
    "\n",
    "  Support Vector Machines (S.V.M.)\n",
    "\n",
    "  Kernel S.V.M.\n",
    "\n",
    "  Decision Tree Classifier\n",
    "\n",
    "  Random Forest Classifier\n",
    "\n",
    "  Naive Bayes\n",
    "\n",
    "  Artificial Neural Network\n",
    "\n",
    "  XG-Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier1 = LogisticRegression(random_state = 0)\n",
    "classifier1.fit(X_train, Y_train)\n",
    "\n",
    "model_Evaluate(classifier1, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier2 = KNeighborsClassifier(n_neighbors = 50, metric = \"minkowski\", p=2)\n",
    "classifier2.fit(X_train, Y_train)\n",
    "\n",
    "model_Evaluate(classifier2, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machines (S.V.M.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier3 = SVC(kernel = \"linear\", random_state = 0)\n",
    "classifier3.fit(X_train, Y_train)\n",
    "\n",
    "model_Evaluate(classifier3, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kernel S.V.M.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier4 = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier4.fit(X_train, Y_train)\n",
    "\n",
    "model_Evaluate(classifier4,X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier5 = DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "classifier5.fit(X_train, Y_train)\n",
    "\n",
    "model_Evaluate(classifier5, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier6 = RandomForestClassifier(n_estimators = 200, criterion = \"entropy\", random_state = 0)\n",
    "classifier6.fit(X_train, Y_train)\n",
    "\n",
    "model_Evaluate(classifier6, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier7 = GaussianNB()\n",
    "classifier7.fit(X_train, Y_train)\n",
    "\n",
    "model_Evaluate(classifier7, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XG-Boost** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:15:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.77\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier8 = XGBClassifier()\n",
    "classifier8.fit(X_train, Y_train)\n",
    "\n",
    "model_Evaluate(classifier8, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Artificial Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.6362 - accuracy: 0.6408 - val_loss: 0.5733 - val_accuracy: 0.7579\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.8168 - val_loss: 0.5501 - val_accuracy: 0.7616\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.4029 - accuracy: 0.8736 - val_loss: 0.5906 - val_accuracy: 0.7711\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.3396 - accuracy: 0.8974 - val_loss: 0.6709 - val_accuracy: 0.7647\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.3010 - accuracy: 0.9109 - val_loss: 0.6551 - val_accuracy: 0.7579\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.2695 - accuracy: 0.9209 - val_loss: 0.7319 - val_accuracy: 0.7605\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.2473 - accuracy: 0.9266 - val_loss: 0.7869 - val_accuracy: 0.7668\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.2323 - accuracy: 0.9305 - val_loss: 0.7704 - val_accuracy: 0.7595\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.2222 - accuracy: 0.9316 - val_loss: 0.8839 - val_accuracy: 0.7600\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.2134 - accuracy: 0.9336 - val_loss: 0.8901 - val_accuracy: 0.7537\n",
      "Epoch 11/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.2069 - accuracy: 0.9351 - val_loss: 0.9164 - val_accuracy: 0.7568\n",
      "Epoch 12/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.2004 - accuracy: 0.9370 - val_loss: 0.9543 - val_accuracy: 0.7568\n",
      "Epoch 13/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1956 - accuracy: 0.9392 - val_loss: 1.0031 - val_accuracy: 0.7616\n",
      "Epoch 14/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1937 - accuracy: 0.9384 - val_loss: 0.9921 - val_accuracy: 0.7674\n",
      "Epoch 15/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1908 - accuracy: 0.9403 - val_loss: 1.0798 - val_accuracy: 0.7637\n",
      "Epoch 16/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1871 - accuracy: 0.9409 - val_loss: 1.1534 - val_accuracy: 0.7553\n",
      "Epoch 17/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1876 - accuracy: 0.9400 - val_loss: 1.0623 - val_accuracy: 0.7611\n",
      "Epoch 18/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1879 - accuracy: 0.9396 - val_loss: 0.9261 - val_accuracy: 0.7442\n",
      "Epoch 19/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1854 - accuracy: 0.9412 - val_loss: 1.1432 - val_accuracy: 0.7579\n",
      "Epoch 20/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1836 - accuracy: 0.9422 - val_loss: 1.1434 - val_accuracy: 0.7626\n",
      "Epoch 21/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1831 - accuracy: 0.9417 - val_loss: 1.0360 - val_accuracy: 0.7505\n",
      "Epoch 22/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1818 - accuracy: 0.9425 - val_loss: 1.1387 - val_accuracy: 0.7563\n",
      "Epoch 23/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1822 - accuracy: 0.9418 - val_loss: 1.1634 - val_accuracy: 0.7563\n",
      "Epoch 24/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1812 - accuracy: 0.9430 - val_loss: 1.1121 - val_accuracy: 0.7574\n",
      "Epoch 25/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1813 - accuracy: 0.9432 - val_loss: 1.0685 - val_accuracy: 0.7511\n",
      "Epoch 26/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1804 - accuracy: 0.9432 - val_loss: 1.1307 - val_accuracy: 0.7521\n",
      "Epoch 27/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1806 - accuracy: 0.9429 - val_loss: 1.0995 - val_accuracy: 0.7532\n",
      "Epoch 28/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1808 - accuracy: 0.9428 - val_loss: 1.0721 - val_accuracy: 0.7505\n",
      "Epoch 29/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1814 - accuracy: 0.9418 - val_loss: 1.0569 - val_accuracy: 0.7532\n",
      "Epoch 30/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1796 - accuracy: 0.9439 - val_loss: 1.1525 - val_accuracy: 0.7505\n",
      "Epoch 31/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1799 - accuracy: 0.9434 - val_loss: 1.0753 - val_accuracy: 0.7484\n",
      "Epoch 32/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1797 - accuracy: 0.9430 - val_loss: 1.0356 - val_accuracy: 0.7395\n",
      "Epoch 33/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1805 - accuracy: 0.9434 - val_loss: 1.0388 - val_accuracy: 0.7511\n",
      "Epoch 34/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1788 - accuracy: 0.9445 - val_loss: 1.0333 - val_accuracy: 0.7379\n",
      "Epoch 35/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1789 - accuracy: 0.9428 - val_loss: 1.0418 - val_accuracy: 0.7505\n",
      "Epoch 36/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1775 - accuracy: 0.9443 - val_loss: 1.1758 - val_accuracy: 0.7521\n",
      "Epoch 37/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1774 - accuracy: 0.9443 - val_loss: 1.0771 - val_accuracy: 0.7442\n",
      "Epoch 38/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1783 - accuracy: 0.9433 - val_loss: 0.9867 - val_accuracy: 0.7447\n",
      "Epoch 39/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1779 - accuracy: 0.9441 - val_loss: 1.0416 - val_accuracy: 0.7495\n",
      "Epoch 40/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1768 - accuracy: 0.9445 - val_loss: 1.0480 - val_accuracy: 0.7484\n",
      "Epoch 41/100\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.1782 - accuracy: 0.9443 - val_loss: 1.0626 - val_accuracy: 0.7521\n",
      "Epoch 42/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1776 - accuracy: 0.9439 - val_loss: 1.0722 - val_accuracy: 0.7484\n",
      "Epoch 43/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1779 - accuracy: 0.9445 - val_loss: 0.9991 - val_accuracy: 0.7542\n",
      "Epoch 44/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1773 - accuracy: 0.9446 - val_loss: 1.0432 - val_accuracy: 0.7558\n",
      "Epoch 45/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1770 - accuracy: 0.9441 - val_loss: 1.0443 - val_accuracy: 0.7553\n",
      "Epoch 46/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1777 - accuracy: 0.9447 - val_loss: 1.0933 - val_accuracy: 0.7595\n",
      "Epoch 47/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1775 - accuracy: 0.9436 - val_loss: 1.0556 - val_accuracy: 0.7479\n",
      "Epoch 48/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1770 - accuracy: 0.9449 - val_loss: 1.1105 - val_accuracy: 0.7563\n",
      "Epoch 49/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1770 - accuracy: 0.9447 - val_loss: 1.0416 - val_accuracy: 0.7484\n",
      "Epoch 50/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1771 - accuracy: 0.9439 - val_loss: 1.1661 - val_accuracy: 0.7547\n",
      "Epoch 51/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1770 - accuracy: 0.9438 - val_loss: 1.0512 - val_accuracy: 0.7484\n",
      "Epoch 52/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1774 - accuracy: 0.9442 - val_loss: 1.0532 - val_accuracy: 0.7474\n",
      "Epoch 53/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1771 - accuracy: 0.9436 - val_loss: 1.0841 - val_accuracy: 0.7484\n",
      "Epoch 54/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1769 - accuracy: 0.9441 - val_loss: 1.1808 - val_accuracy: 0.7511\n",
      "Epoch 55/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1768 - accuracy: 0.9439 - val_loss: 1.0812 - val_accuracy: 0.7447\n",
      "Epoch 56/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1769 - accuracy: 0.9438 - val_loss: 1.0624 - val_accuracy: 0.7395\n",
      "Epoch 57/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1767 - accuracy: 0.9447 - val_loss: 1.0876 - val_accuracy: 0.7416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1764 - accuracy: 0.9441 - val_loss: 1.0717 - val_accuracy: 0.7405\n",
      "Epoch 59/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1757 - accuracy: 0.9457 - val_loss: 1.1122 - val_accuracy: 0.7411\n",
      "Epoch 60/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1761 - accuracy: 0.9439 - val_loss: 1.1771 - val_accuracy: 0.7463\n",
      "Epoch 61/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1757 - accuracy: 0.9454 - val_loss: 1.1254 - val_accuracy: 0.7442\n",
      "Epoch 62/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1762 - accuracy: 0.9436 - val_loss: 1.2092 - val_accuracy: 0.7479\n",
      "Epoch 63/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1755 - accuracy: 0.9441 - val_loss: 1.2250 - val_accuracy: 0.7463\n",
      "Epoch 64/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.9447 - val_loss: 1.1391 - val_accuracy: 0.7405\n",
      "Epoch 65/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1761 - accuracy: 0.9442 - val_loss: 1.1293 - val_accuracy: 0.7432\n",
      "Epoch 66/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1758 - accuracy: 0.9445 - val_loss: 1.1139 - val_accuracy: 0.7411\n",
      "Epoch 67/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.9450 - val_loss: 1.2255 - val_accuracy: 0.7405\n",
      "Epoch 68/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1766 - accuracy: 0.9443 - val_loss: 1.2046 - val_accuracy: 0.7426\n",
      "Epoch 69/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1753 - accuracy: 0.9443 - val_loss: 1.1726 - val_accuracy: 0.7395\n",
      "Epoch 70/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1749 - accuracy: 0.9451 - val_loss: 1.2328 - val_accuracy: 0.7368\n",
      "Epoch 71/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.9445 - val_loss: 1.1700 - val_accuracy: 0.7332\n",
      "Epoch 72/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1749 - accuracy: 0.9457 - val_loss: 1.1792 - val_accuracy: 0.7374\n",
      "Epoch 73/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1751 - accuracy: 0.9455 - val_loss: 1.2260 - val_accuracy: 0.7458\n",
      "Epoch 74/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1747 - accuracy: 0.9454 - val_loss: 1.1719 - val_accuracy: 0.7389\n",
      "Epoch 75/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1745 - accuracy: 0.9457 - val_loss: 1.1122 - val_accuracy: 0.7247\n",
      "Epoch 76/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1743 - accuracy: 0.9454 - val_loss: 1.2153 - val_accuracy: 0.7426\n",
      "Epoch 77/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1744 - accuracy: 0.9449 - val_loss: 1.2777 - val_accuracy: 0.7332\n",
      "Epoch 78/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1742 - accuracy: 0.9457 - val_loss: 1.2185 - val_accuracy: 0.7342\n",
      "Epoch 79/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1760 - accuracy: 0.9442 - val_loss: 1.0853 - val_accuracy: 0.7195\n",
      "Epoch 80/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1745 - accuracy: 0.9458 - val_loss: 1.2965 - val_accuracy: 0.7326\n",
      "Epoch 81/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1741 - accuracy: 0.9458 - val_loss: 1.3724 - val_accuracy: 0.7363\n",
      "Epoch 82/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9457 - val_loss: 1.3118 - val_accuracy: 0.7321\n",
      "Epoch 83/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9451 - val_loss: 1.3509 - val_accuracy: 0.7332\n",
      "Epoch 84/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1738 - accuracy: 0.9457 - val_loss: 1.3990 - val_accuracy: 0.7332\n",
      "Epoch 85/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9457 - val_loss: 1.3469 - val_accuracy: 0.7316\n",
      "Epoch 86/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9455 - val_loss: 1.3674 - val_accuracy: 0.7337\n",
      "Epoch 87/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9457 - val_loss: 1.2944 - val_accuracy: 0.7295\n",
      "Epoch 88/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1738 - accuracy: 0.9453 - val_loss: 1.3460 - val_accuracy: 0.7284\n",
      "Epoch 89/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1740 - accuracy: 0.9457 - val_loss: 1.3692 - val_accuracy: 0.7353\n",
      "Epoch 90/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9455 - val_loss: 1.2370 - val_accuracy: 0.7326\n",
      "Epoch 91/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1757 - accuracy: 0.9442 - val_loss: 1.1876 - val_accuracy: 0.7300\n",
      "Epoch 92/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1749 - accuracy: 0.9441 - val_loss: 1.2618 - val_accuracy: 0.7337\n",
      "Epoch 93/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1747 - accuracy: 0.9451 - val_loss: 1.2288 - val_accuracy: 0.7284\n",
      "Epoch 94/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1749 - accuracy: 0.9447 - val_loss: 1.0538 - val_accuracy: 0.7153\n",
      "Epoch 95/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1752 - accuracy: 0.9451 - val_loss: 1.1677 - val_accuracy: 0.7242\n",
      "Epoch 96/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1735 - accuracy: 0.9458 - val_loss: 1.1773 - val_accuracy: 0.7247\n",
      "Epoch 97/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1731 - accuracy: 0.9458 - val_loss: 1.1621 - val_accuracy: 0.7258\n",
      "Epoch 98/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1729 - accuracy: 0.9459 - val_loss: 1.2111 - val_accuracy: 0.7316\n",
      "Epoch 99/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1733 - accuracy: 0.9455 - val_loss: 1.1254 - val_accuracy: 0.7195\n",
      "Epoch 100/100\n",
      "238/238 [==============================] - 1s 3ms/step - loss: 0.1729 - accuracy: 0.9455 - val_loss: 1.2189 - val_accuracy: 0.7316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22fd5d351f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=40, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=10, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=5, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=2, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann.fit(X_train, Y_train, batch_size = 32, epochs = 100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test , y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon evaluating all the models we can conclude that the **Logistic Regression** is the best model for the above-given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our problem statement, **Logistic Regression** is following the principle of **Occam’s Razor** which defines that for a particular problem statement if the data has no assumption, then **the simplest model works the best**. Since our dataset does not have any assumptions and Logistic Regression is a simple model, therefore the concept holds true for the above-mentioned dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
